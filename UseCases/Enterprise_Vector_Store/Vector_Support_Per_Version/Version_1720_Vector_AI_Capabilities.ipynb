{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8b5c16-e8dd-4530-b4c5-0c8210640620",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Vector analytics and AI functionality per database version - 17.20 and Vantage 3.0\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Overview</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Teradata Vantage provides a suite in-database analytic capabilities for Vector embedding and analytics with support across multiple database versions.  This notebook series reviews these capablities per database version, including:</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Database Version 17.20+ and VantageCloud Enterprise 3.0</b>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Bring-Your-Own-Model (BYOM)</b> capabilities allow users to generate vector embeddings using open-source models serialized as ONNX format</li>\n",
    "    <li><b>Vector data</b> stored as FLOAT columns in normal database tables</li>\n",
    "    <li><b>Similarity analysis</b> using native ClearScape Analytics functions - <b>Vector Distance</b> and <b>KMeans</b></li>\n",
    "    </ul>\n",
    "    \n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>VantageCloud Enterprise 3.1+</b>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>AI Analytic Functions</b> that leverage <b>Cloud-based LLMs</b> for text analytics, including Vector Embedding functions and RAG</li>\n",
    "    <li><b>VECTOR Datatype</b> Varbyte-based array of vector data stored as single column</li>\n",
    "    <li><b>Normalization</b> of vector data for efficient similarity analysis</li>\n",
    "    <li><b>Similarity analysis</b> using VECTOR DATATYPE and additional functions</li>\n",
    "    </ul>\n",
    "    \n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>VantageCloud Lake</b>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>In-platform GPUs</b> leveraging Analytic Compute Clusters for high-scale vector embedding and other Large Language Model tasks</li>\n",
    "    <li><b>Enterprise Vector Store APIs</b> for creating and managing vector data using Python and/or REST</li>\n",
    "    <li><b>Similarity Search and RAG APIs</b> using Python</li>\n",
    "    <li><b>Vector Store UI</b> for managing vector data</li>\n",
    "    </ul>\n",
    "\n",
    "<p style = 'font-size:28px;font-family:Arial;color:#00233C'><b>Demonstration Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>All of these demonstrations are based off of a small sample data set of Amazon book reviews.</p>\n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Prerequsites</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This only needs to be run once for the user environment - restart the kernel after installing the proper packages.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e33bf-d7d5-4e67-9adf-04f144b23160",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db37c8-96e0-494f-b333-49a0f5f47cd9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Imports</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6423cf9-8911-4c57-bf81-d0fa68b02823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "from teradatagenai import TextAnalyticsAI, TeradataAI, load_data\n",
    "from teradatasqlalchemy.types import *\n",
    "\n",
    "import getpass, os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set display options for dataframes, plots, and warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "# Setting up BYOM install location.\n",
    "configure.byom_install_location = 'td_mldb'\n",
    "\n",
    "# use an embeddings model from the Teradata repo\n",
    "model_name = 'multilingual-e5-small'\n",
    "number_dimensions_output = 384\n",
    "model_file_name = 'model.onnx'\n",
    "\n",
    "# load vars json\n",
    "with open('vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Database login information\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24e41e-2267-4cdb-abc1-64b1d1c05fce",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Features supported in database version 17.20 and Vantage Enterprise 3.0\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will review the the process of vector embedding and similarity search using <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_Lake_VMware/Teradata-VantageTM-Bring-Your-Own-Model-User-Guide/Welcome-to-Bring-Your-Own-Model'>Bring Your Own Model (BYOM)</a> as the primary mechanism for Vector Embedding:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'>\n",
    "    <tr><td style = 'vertical-align:top' width = '40%'>    \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Load the model</b> into the database using the teradataml Python Package</li>\n",
    "    <br>\n",
    "    <li><b>Generate Embeddings</b> using the ONNXEmbeddings function</li>\n",
    "    <br>\n",
    "    <li><b>Similarity analysis</b> using VECTORDISTANCE and KMEANS</li>\n",
    "    </ol>\n",
    "        </td><td style = 'text-align:center'><img src = 'images/Pattern_1.png' width = '300'></td></tr>\n",
    "</table>\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Optional - Download the model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Teradata Vantage can execute various AI and ML models as functions running as native <b>MPP</b> functions inside the database. This includes models for vector embedding, text summarization, etc.  Models are loaded as ONNX (Open Neural Network eXchange) formatted files.  ONNX versions of popular models are available in the <a href = 'https://huggingface.co/Teradata'>Teradata Hugging Face repository</a>.  Other models can be converted to this format using tools such as <a href = 'https://pypi.org/project/optimum/'>optimum</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f86cb-1d36-48a4-ba4d-89910dfc10fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional - Download Model from Teradata HuggingFace Page\n",
    "if False:\n",
    "    hf_hub_download(repo_id = f'Teradata/{model_name}', filename = f'onnx/{model_file_name}', local_dir = os.getcwd())\n",
    "    hf_hub_download(repo_id = f'Teradata/{model_name}', filename = 'tokenizer.json', local_dir = os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2d694-e6cf-4788-8e37-5cecf99894c8",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Required - Connect to the database</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Initiate the connection to the target system.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8830b74-9741-4261-bf14-06c3a69f0a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create Connection to Vantage\n",
    "\n",
    "eng = create_context(host = host, username = username, password = password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a61348-5599-44cf-8d60-3c47b81a1363",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 1 - Optional - Load the model into the database</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First, connect to the target system.  Next, use teradataml functions to load the models to a specified table.  This table must have enough room to store model; see the <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_Lake_VMware/Teradata-VantageTM-Bring-Your-Own-Model-User-Guide/Preparing-to-Use-BYOM/Creating-Model-Tables'>user guide</a> for more details.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note</b> this step is optional if the model has already been loaded.  The model files can be quite large, so this is typically a one-time operation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2aed0-5c44-478f-943b-f31ef615789f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Models into Vantage - the additional_columns argument can be used to pass additional metadata\n",
    "if False:\n",
    "    # a) Embedding model\n",
    "    save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = os.path.join(os.getcwd(), 'onnx', model_file_name),\n",
    "              table_name = 'embeddings_models',\n",
    "              schema_name = 'ai_demos',\n",
    "              additional_columns = {'Dimensions':number_dimensions_output})\n",
    "\n",
    "    # b) Tokenizer\n",
    "    save_byom(model_id = model_name, # must be unique in the models table\n",
    "                  model_file = 'tokenizer.json',\n",
    "                  schema_name = 'ai_demos',\n",
    "                  table_name = 'embeddings_tokenizers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2de725-97a7-49b6-bee4-9d5f27b95c0e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Inspect the source data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use simple python methods to inspect the Amazon Reviews data.  This code creates a teradataml DataFrame, which represents the data in the database which could extend to millions or billions of rows.  Data is not moved, and users can perform common data management and analytics functions that will run at scale on the target system.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d817396-c049-43e8-9d77-a3fa441c1f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf_reviews = DataFrame('\"demo\".\"amazon_reviews_25\"')\n",
    "tdf_reviews.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3b3a3-c6c1-48c9-9a3a-b77f8e336d2f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 2 - Generate embeddings</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_Lake_VMware/Teradata-VantageTM-Bring-Your-Own-Model-User-Guide/BYOM-Functions/ONNXEmbeddings'>ONNXEmbeddings</a> function can be expressed in SQL or in python using the teradatagenai library.  Each method takes multiple arguments, primarily:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Input Table</b> Either a query, table, or view that returns the source content.  This function assumes the text field is named 'txt'.</li>\n",
    "    <li><b>Model Table</b> Can be a table or view if the entity contains a single model.  Else, pass a query that returns the single row for the selected model</li>\n",
    "    <li><b>Tokenizer Table</b> As above; a table or view if single model table, or a query selecting a single row</li>\n",
    "</ol> \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>SQL version:</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876cc30-9e8a-4d51-9402-8d92468ac713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_table = 'demo.amazon_reviews_25'\n",
    "\n",
    "qry = f'''\n",
    "SELECT *\n",
    "FROM td_mldb.ONNXEmbeddings(\n",
    "        ON (SELECT TOP 1 id, rev_text AS txt FROM {input_table}) AS InputTable\n",
    "        ON (SELECT * FROM ai_demos.embeddings_models WHERE model_id = '{model_name}') AS ModelTable DIMENSION\n",
    "        ON (SELECT model AS tokenizer FROM ai_demos.embeddings_tokenizers WHERE model_id = '{model_name}') AS TokenizerTable DIMENSION\n",
    "        USING\n",
    "            Accumulate('id', 'txt')\n",
    "            ModelOutputTensor('sentence_embedding')\n",
    "            EnableMemoryCheck('false')\n",
    "            OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "            OverwriteCachedModel('true')\n",
    "    ) AS embedding_output;\n",
    "'''\n",
    "\n",
    "tdf = DataFrame.from_query(qry)\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f249814-a15a-4706-ac6f-b70117171308",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python version</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For python developers, the <a href = 'https://docs.teradata.com/r/Lake-Analyze-Your-Data-with-ClearScape-AnalyticsTM/Teradata-Package-for-Generative-AI'>teradatagenai</a> python library can both connect to cloud-based LLM services as well as instantiate private models running <b>at scale</b> on local CPU or GPU compute. In the case of systems that don't have GPU support, the ONNXEmbeddings function will be used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178a5f4-2480-4bd7-8190-dc1f0362d925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_onnx = TeradataAI(\n",
    "    api_type = 'onnx',\n",
    "    model_schema_name = 'ai_demos',\n",
    "    model_name = model_name,\n",
    "    model_id = model_name,\n",
    "    model_table_name = 'embeddings_models',\n",
    "    tokenizer_schema_name = 'ai_demos',\n",
    "    tokenizer_id = model_name,\n",
    "    tokenizer_table_name = 'embeddings_tokenizers')\n",
    "\n",
    "# Instantiate the TextAnalyticsAI class with the ONNX model.\n",
    "obj = TextAnalyticsAI(llm=llm_onnx)\n",
    "\n",
    "tdf_embeddings = obj.embeddings(data = tdf_reviews,\n",
    "                                column = 'rev_text', \n",
    "                                accumulate = 'id',\n",
    "                                output_format = f'FLOAT32({number_dimensions_output})',\n",
    "                                model_output_tensor = 'SENTENCE_EMBEDDING')\n",
    "\n",
    "tdf_embeddings.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ac8d3-f67d-47f1-a77c-280421b5e323",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Store the embeddings</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For improved performance, store the embeddings in a table.  In this example, a volatile table is used so cleanup is automatic.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98deba-4ad9-4e52-aa14-69e50ca2a387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_table = 'demo.amazon_reviews_25'\n",
    "\n",
    "qry = f'''\n",
    "CREATE VOLATILE TABLE review_embeddings AS (\n",
    "SELECT *\n",
    "FROM td_mldb.ONNXEmbeddings(\n",
    "        ON (SELECT id, rev_text AS txt FROM {input_table}) AS InputTable\n",
    "        ON (SELECT * FROM ai_demos.embeddings_models WHERE model_id = '{model_name}') AS ModelTable DIMENSION\n",
    "        ON (SELECT model AS tokenizer FROM ai_demos.embeddings_tokenizers WHERE model_id = '{model_name}') AS TokenizerTable DIMENSION\n",
    "        USING\n",
    "            Accumulate('id', 'txt')\n",
    "            ModelOutputTensor('sentence_embedding')\n",
    "            EnableMemoryCheck('false')\n",
    "            OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "            OverwriteCachedModel('true')\n",
    "    ) AS embedding_output) WITH DATA\n",
    "ON COMMIT PRESERVE ROWS;\n",
    "'''\n",
    "\n",
    "execute_sql(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27097c91-5d1a-4748-9490-79c1bf36ad32",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 3 - Perform Vector Distance calculations</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ClearScape Analytics function <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Analytics-Database-Analytic-Functions/Model-Training-Functions/TD_VectorDistance'>TD_VectorDistance</a> function will take a table of input Vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs.  Since this function scans every row and performs the distance calculation, it is resource-intensive and usually suited to a lower number of records.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This example will use an input query to perform the distance calculations:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Pass the input text to the ONNXEmbedings function</li>\n",
    "    <li>Use the resulting embeddings as a dimension to the distance function</li>\n",
    "    <li>Examples are provided in python and SQL</li>\n",
    "    </ol>\n",
    "    \n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Embed the input text</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Rewrite the query to use input text for embedding.  Show the result.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1b7c9-e9c0-4066-a2f7-a43749aa4f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_term = input('Please enter a search term (e.g. \"poetry\"): ')\n",
    "\n",
    "qry = f'''\n",
    "SELECT *\n",
    "FROM td_mldb.ONNXEmbeddings(\n",
    "        ON (SELECT 1 id, '{search_term}' AS txt) AS InputTable\n",
    "        ON (SELECT * FROM ai_demos.embeddings_models WHERE model_id = '{model_name}') AS ModelTable DIMENSION\n",
    "        ON (SELECT model AS tokenizer FROM ai_demos.embeddings_tokenizers WHERE model_id = '{model_name}') AS TokenizerTable DIMENSION\n",
    "        USING\n",
    "            Accumulate('id', 'txt')\n",
    "            ModelOutputTensor('sentence_embedding')\n",
    "            EnableMemoryCheck('false')\n",
    "            OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "            OverwriteCachedModel('true')\n",
    "    ) AS embedding_output;\n",
    "'''\n",
    "\n",
    "tdf_input = DataFrame.from_query(qry)\n",
    "print('Vector Representation of the input search term:')\n",
    "ipydisplay(tdf_input.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc32fc-a28c-451a-abd1-b6ce2defc824",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Perform Vector Distance calculation</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the volatile review embeddings table as the Reference table, and the question above as the Target table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa7c74-eb2d-4e90-937e-d7198ab667a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_table = 'review_embeddings'\n",
    "\n",
    "dist_qry = f'''\n",
    "SELECT TOP 10 target_id, reference_id, distancetype, ABS(cast(distance as decimal(36,8))) as distance FROM TD_VECTORDISTANCE (\n",
    "    ON ({qry[:-2]}) AS TargetTable\n",
    "    ON {reference_table} AS ReferenceTable DIMENSION\n",
    "USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[2:385]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[2:385]')\n",
    "    DistanceMeasure('cosine')\n",
    "    topk(10)\n",
    ") AS dt order by 4;\n",
    "'''\n",
    "tdf_distance = DataFrame.from_query(dist_qry)\n",
    "tdf_distance.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649f5ef-6d59-4836-b85e-86085dca1fce",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Join the results back to the original complaints and topics</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demonstration, expand all SQL to show the full query.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c70c15-367c-44bb-a16b-bbd14c10efd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_term = input('Please enter a search term (e.g \"philosophy\"): ')\n",
    "\n",
    "join_qry = f'''\n",
    "SELECT c.id review_id, c.rev_text review, d.distance\n",
    "\n",
    "FROM (SELECT target_id, reference_id, distancetype, ABS(cast(distance as decimal(36,8))) as distance FROM TD_VECTORDISTANCE ( \n",
    "    ON \n",
    "        (SELECT *\n",
    "        FROM td_mldb.ONNXEmbeddings(\n",
    "                ON (SELECT 1 id, '{search_term}' AS txt) AS InputTable\n",
    "                ON (SELECT * FROM ai_demos.embeddings_models WHERE model_id = '{model_name}') AS ModelTable DIMENSION\n",
    "                ON (SELECT model AS tokenizer FROM ai_demos.embeddings_tokenizers WHERE model_id = '{model_name}') AS TokenizerTable DIMENSION\n",
    "                USING\n",
    "                    Accumulate('id', 'txt')\n",
    "                    ModelOutputTensor('sentence_embedding')\n",
    "                    EnableMemoryCheck('false')\n",
    "                    OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "                    OverwriteCachedModel('true')\n",
    "            ) AS embedding_output\n",
    "    ) AS TargetTable\n",
    "    ON {reference_table} AS ReferenceTable DIMENSION\n",
    "USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[2:385]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[2:385]')\n",
    "    DistanceMeasure('cosine')\n",
    "    topk(10)\n",
    ") AS dt) d\n",
    "    \n",
    "JOIN {input_table} c\n",
    "    ON c.id = d.reference_id;\n",
    "'''\n",
    "tdf_distance = DataFrame.from_query(join_qry)\n",
    "tdf_distance.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab67019-e7da-4412-8d89-305c1dc9d49f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Version</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Perform the following operations using python classes and methods:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Perform vector embedding of the query text</li>\n",
    "    <li>Execute Vector Distance function</li>\n",
    "    <li>Assemble final data set</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b20102-d811-404e-a8db-bb5616a4b171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_term = input('Please enter a search term (e.g. \"poetry\"): ')\n",
    "\n",
    "# re-initialize the byom object\n",
    "llm_onnx = TeradataAI(\n",
    "    api_type = 'onnx',\n",
    "    model_schema_name = 'ai_demos',\n",
    "    model_name = model_name,\n",
    "    model_id = model_name,\n",
    "    model_table_name = 'embeddings_models',\n",
    "    tokenizer_schema_name = 'ai_demos',\n",
    "    tokenizer_id = model_name,\n",
    "    tokenizer_table_name = 'embeddings_tokenizers')\n",
    "\n",
    "# Instantiate the TextAnalyticsAI class with the ONNX model.\n",
    "obj = TextAnalyticsAI(llm=llm_onnx)\n",
    "\n",
    "# generate an embedded representation of the search term\n",
    "tdf_search_embedding = obj.embeddings(data = DataFrame.from_query(f'''SELECT 1 id, '{search_term}' AS txt'''),\n",
    "                                column = 'txt', \n",
    "                                accumulate = 'id',\n",
    "                                output_format = f'FLOAT32({number_dimensions_output})',\n",
    "                                model_output_tensor = 'SENTENCE_EMBEDDING')\n",
    "tdf_search_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d5e82-339a-4042-8ace-3a996d19edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table = 'review_embeddings'\n",
    "\n",
    "tdf_dist = VectorDistance(target_data = tdf_search_embedding,\n",
    "                          reference_data = DataFrame(reference_table),\n",
    "                          target_id_column = 'id',\n",
    "                          ref_id_column = 'id',\n",
    "                          target_feature_columns = [f'emb_{str(i)}' for i in range(384)],\n",
    "                          ref_feature_columns = [f'emb_{str(i)}' for i in range(384)],\n",
    "                          topk = 10).result\n",
    "                          \n",
    "tdf_dist                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ee23f-66b6-4677-b3f5-9be48d28e920",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 3a - KMeans for fast search</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The native KMeans function can be used to create an Inverted File Index, where each cluster is an index.</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'>\n",
    "    <tr><td style = 'vertical-align:top' width = '40%'>   \n",
    "        <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Partitions data into clusters (Voronoi cells)</li>\n",
    "    <li>Requires training to establish centroids (indexes)</li>\n",
    "    <li>Using Teradata MPP architecture<ul><li>Distance computation from centroids is parallelized</li>\n",
    "        <li>Distance computation from data points of a centroid is parallelized</li></ul></li>\n",
    "            <li>Approximate approach. Trades off accuracy with speed. Query vectors near the boundary of a cluster may have nearest neighbor in the neighboring cluster</li>\n",
    "    </ul>\n",
    "</td><td style = 'text-align:center'><img src = 'images/KMEANS.png' width = '300'></td></tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Steps in the process:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Train the KMeans model - choosing an appropriate number of clusters for the volume of data.  This function returns two objects<ul><li>Model Table which contains cluster ID and centroid values</li><li>Cluster Assigments - the assigned cluster ID for each row in the source table</li></ul></li>\n",
    "    <li>Use the Model Table as an index</li>\n",
    "    <li>Execute Vector Distance on the index, returning N closest centroids</li>\n",
    "    <li>Execute Vector distance on the original data, using the cluster assignments to filter the original data set</li>\n",
    "</ol>\n",
    "    \n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Train the KMeans model</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use SQL or Python interfaces to execute the <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Database-Analytic-Functions/Model-Training-Functions/TD_KMeans'>TD_KMEANS</a> function.  In this case, generate the model (with centroid values) AND cluster assignments:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb217a-e183-4366-b6af-f5f04b896e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    execute_sql('DROP TABLE kmeans_model;')\n",
    "    execute_sql('DROP TABLE cluster_assignments;')\n",
    "except Exception as e:\n",
    "    if 'does not exist.' in str(e):\n",
    "        pass\n",
    "\n",
    "# use the embedding table created above\n",
    "input_table = 'review_embeddings'\n",
    "\n",
    "\n",
    "qry = f'''\n",
    "CREATE VOLATILE TABLE cluster_assignments AS (\n",
    "SELECT * FROM TD_KMeans (\n",
    "    ON {input_table} AS InputTable\n",
    "    OUT VOLATILE TABLE ModelTable(kmeans_model)\n",
    "USING\n",
    "    IdColumn('id')\n",
    "    TargetColumns('[2:385]')\n",
    "    StopThreshold(0.0395)\n",
    "    NumClusters(4)\n",
    "    MaxIterNum(3)\n",
    "    OutputClusterAssignment('true')\n",
    ")AS dt) WITH DATA\n",
    "ON COMMIT PRESERVE ROWS;\n",
    "'''\n",
    "execute_sql(qry)\n",
    "\n",
    "ipydisplay(Markdown('Model: '))\n",
    "ipydisplay(DataFrame('kmeans_model').to_pandas())\n",
    "\n",
    "ipydisplay(Markdown('Cluster Assignments: '))\n",
    "ipydisplay(DataFrame('cluster_assignments').to_pandas().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4dc06-4dbd-4ec9-8b06-dd3471c0afb1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Create Index table</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the model table as input to the Inverted File Index</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4f08c-d40a-43cb-8fa2-8b911a11e32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    execute_sql('DROP TABLE kmeans_index;')\n",
    "except Exception as e:\n",
    "    if 'does not exist.' in str(e):\n",
    "        pass\n",
    "\n",
    "qry = f'''\n",
    "CREATE VOLATILE TABLE kmeans_index AS (\n",
    "SELECT * FROM kmeans_model\n",
    "WHERE td_clusterid_kmeans IS NOT NULL) WITH DATA\n",
    "PRIMARY INDEX(td_clusterid_kmeans)\n",
    "ON COMMIT PRESERVE ROWS;'''\n",
    "execute_sql(qry)\n",
    "\n",
    "ipydisplay(Markdown('Index Table: '))\n",
    "ipydisplay(DataFrame('kmeans_index').to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b1bee-79a7-4de4-aaf5-d7be1f4758bc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Execute Vector Distance against index</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Return N (2 in this case) cluster assignments</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92fd89-61fa-438a-8a8e-cd709f4229ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_term = input('Please enter a search term: ')\n",
    "search_term = 'Best books on philosophy'\n",
    "reference_table = 'kmeans_index'\n",
    "\n",
    "cluster_qry = f'''\n",
    "SELECT reference_id cluster_id, distancetype, ABS(cast(distance as decimal(36,8))) as distance FROM TD_VECTORDISTANCE (\n",
    "    ON \n",
    "        (SELECT *\n",
    "        FROM td_mldb.ONNXEmbeddings(\n",
    "                ON (SELECT 1 id, '{search_term}' AS txt) AS InputTable\n",
    "                ON (SELECT * FROM ai_demos.embeddings_models WHERE model_id = '{model_name}') AS ModelTable DIMENSION\n",
    "                ON (SELECT model AS tokenizer FROM ai_demos.embeddings_tokenizers WHERE model_id = '{model_name}') AS TokenizerTable DIMENSION\n",
    "                USING\n",
    "                    Accumulate('id', 'txt')\n",
    "                    ModelOutputTensor('sentence_embedding')\n",
    "                    EnableMemoryCheck('false')\n",
    "                    OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "                    OverwriteCachedModel('true')\n",
    "            ) AS embedding_output\n",
    "    ) AS TargetTable\n",
    "    ON {reference_table} AS ReferenceTable DIMENSION\n",
    "USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[2:385]')\n",
    "    RefIDColumn('td_clusterid_kmeans')\n",
    "    RefFeatureColumns('[1:384]')\n",
    "    DistanceMeasure('cosine')\n",
    "    topk(2)\n",
    ") AS dt;\n",
    "'''\n",
    "tdf_distance = DataFrame.from_query(cluster_qry)\n",
    "ipydisplay(Markdown(f'Search term: {search_term}'))\n",
    "ipydisplay(tdf_distance.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ec43e-b84e-45ba-9426-85ba11d79606",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Use Cluster ID as a filter to Vector Distance</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Pass the top two closest cluster centroids as a filter to reduce the number of rows to scan with Vector Distance.  For this demo, use the filter explicitly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c2f0f-ad0d-4353-a5f1-6b050c3d697a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_term = input('Please enter a search term: ')\n",
    "search_term = 'Best books on philosophy'\n",
    "input_table = 'demo.amazon_reviews_25'\n",
    "reference_table = 'review_embeddings'\n",
    "cluster_ids = '0,3'\n",
    "\n",
    "join_qry = f'''\n",
    "SELECT c.id review_id, c.rev_text review, d.distance\n",
    "\n",
    "FROM (SELECT target_id, reference_id, distancetype, ABS(cast(distance as decimal(36,8))) as distance FROM TD_VECTORDISTANCE (\n",
    "    ON \n",
    "        (SELECT *\n",
    "        FROM td_mldb.ONNXEmbeddings(\n",
    "                ON (SELECT 1 id, '{search_term}' AS txt) AS InputTable\n",
    "                ON (SELECT * FROM ai_demos.embeddings_models WHERE model_id = '{model_name}') AS ModelTable DIMENSION\n",
    "                ON (SELECT model AS tokenizer FROM ai_demos.embeddings_tokenizers WHERE model_id = '{model_name}') AS TokenizerTable DIMENSION\n",
    "                USING\n",
    "                    Accumulate('id', 'txt')\n",
    "                    ModelOutputTensor('sentence_embedding')\n",
    "                    EnableMemoryCheck('false')\n",
    "                    OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "                    OverwriteCachedModel('true')\n",
    "            ) AS embedding_output\n",
    "    ) AS TargetTable\n",
    "    ON \n",
    "        (SELECT * FROM {reference_table} \n",
    "        WHERE id IN (SELECT id FROM cluster_assignments WHERE td_clusterid_kmeans IN ({cluster_ids}))\n",
    "    )  AS ReferenceTable DIMENSION\n",
    "USING\n",
    "    TargetIDColumn('id')\n",
    "    TargetFeatureColumns('[2:385]')\n",
    "    RefIDColumn('id')\n",
    "    RefFeatureColumns('[2:385]')\n",
    "    DistanceMeasure('cosine')\n",
    "    topk(10)\n",
    ") AS dt) d\n",
    "    \n",
    "JOIN {input_table} c\n",
    "    ON c.id = d.reference_id;\n",
    "'''\n",
    "tdf_distance = DataFrame.from_query(join_qry)\n",
    "ipydisplay(Markdown(f'Search term: {search_term}'))\n",
    "ipydisplay(tdf_distance.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c9d60-8cd3-46e7-a9f9-1d1c0234480a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Vector embedding and analytics - 17.20 and Vantage 3.0</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can generate vector embeddings <b>in-database</b> and then use native ClearScape Analytics functions to perform high-scale, parallelized similarity search</p>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Cleanup</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Disconnect from the database to remove all volatile tables.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e43f9-6d83-4775-a9fa-be1261ebb6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
