{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Accelerate the development and deployment of real-world AI-powered analytics with Teradata VantageCloud and open-source language models\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"../../../images/TeradataLogo.png\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<hr>\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#00233C'>Demonstrations Overview</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstrations illustrate the end-to-end process of how organizations can utilize VantageCloud Lake <b>GPU-enabled Analytic Cluster</b> architecture to run open-source large language models at massive parallelism and scale, and then leverage these next-generation capabilities in ad-hoc analytics, development, and operational processing.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This notebook contains several high-level demonstrations that can be run together or individually, and are designed to illustrate;</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Container Management</b>.  Administrators can create and manage <b>secure, custom</b> runtime containers that will host any number of models and model artifacts to unlock GPU-augmented analytics</li>\n",
    "    <li><b>Use-case Development</b>. Developers and data scientists can use familiar tools and techniques to develop and test analytic processing that combinines traditional analytics and data processing with open-source Hugging Face models <b>at scale</b>.  The use case illustrated here is a simple <b>Vector Embedding</b> of retail customer comments</li>\n",
    "    <li><b>Operationalization</b>. Deploy the AI-augmented pipeline <b>operationally</b>; unlocking the power of these advanced techniques to the broadest set of tools, applications, and consumers</li>\n",
    "    </ol>\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#00233C'>End-to-End workflow</b>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The high level process is as follows:</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'>\n",
    "    <tr><td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>The Data Scientist conducts analytics activities using his or her own python tools and packages of choice, then connects to VantageCloud Lake through teradataml client library and teradatasql python driver.</li>\n",
    "                <br>      \n",
    "                <li>Teradataml provides APIs to create and manage custom runtime environments; including custom libraries, dependencies, model artifacts, and scoring scripts.  The user can leverage these APIs to create one or many custom, dedicated environments to host their code.</li>\n",
    "                <br>\n",
    "                <li>The Data Scientist will then execute their pipeline that will;\n",
    "                    <ul style = 'width:100%;table-layout:fixed;font-family:Arial;color:#00233C'><li>Call ClearScape Analytics functions on Compute Clusters (data prep, transformation, etc.)</li>\n",
    "                        <li>Prepared data is passed to the python container running in parallel on cluster nodes.</li>\n",
    "                        <li>Results (inference/predictions) are returned as \"virtual\" dataframes; where the data resides <b>in Vantage</b></li>\n",
    "                    </ul></li>\n",
    "                <br>\n",
    "                <li>Worfklow can be operationalized using SQL, and results can be returned to common BI tools, persisted as part of an ETL process, or embedded in application code</li>\n",
    "            </ol>\n",
    "        </td><td><img src = 'images/BYOLLM_Overview.png' width = '600'></td></tr>\n",
    "</table>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Installation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If necessary, install required client packages for the demonstrations.  User may need to restart the Jupyter kernel after installation.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Python Package Imports</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Standard practice to import required packages and libraries; execute this cell to import packages for Teradata automation as well as machine learning, analytics, utility, and data management packages.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "from oaf_utils import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from itables import init_notebook_mode\n",
    "import itables.options as opt\n",
    "\n",
    "# Set display options for dataframes, plots, and warnings\n",
    "\n",
    "opt.style=\"table-layout:auto;width:auto;float:left\"\n",
    "opt.columnDefs = [{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
    "init_notebook_mode(all_interactive=True)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "# load vars json\n",
    "with open('../../../vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Database login information\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['business_users'][1]['username']\n",
    "password = session_vars['hierarchy']['users']['business_users'][1]['password']\n",
    "\n",
    "# UES Authentication information\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "configure.ues_url = ues_url\n",
    "pat_token = session_vars['hierarchy']['users']['business_users'][1]['pat_token']\n",
    "pem_file = session_vars['hierarchy']['users']['business_users'][1]['key_file']\n",
    "\n",
    "\n",
    "compute_group = session_vars['hierarchy']['users']['business_users'][1]['compute_group']\n",
    "\n",
    "\n",
    "# get the current python version to match deploy a custom container\n",
    "python_version = str(sys.version_info[0]) + '.' + str(sys.version_info[1])\n",
    "print(f'Using Python version {python_version} for user environment')\n",
    "\n",
    "\n",
    "# Hugging Face model for the demo\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "# a list of required packages to install in the custom OAF container\n",
    "# modify this if using different models or design patterns\n",
    "pkgs = ['transformers',\n",
    "        'torch',\n",
    "        'sentencepiece',\n",
    "        'numpy',\n",
    "        'pandas',\n",
    "        'sentence-transformers',\n",
    "        'dill']\n",
    "\n",
    "# container name - set here for easier notebook navigation\n",
    "### User will also be asked to change it ###\n",
    "oaf_name = 'oaf_demo_env'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Connect to the database</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>After connecting, check cluster status. Start it if necessary - note the cluster only needs to be running to execute the APPLY sections of the demo.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "\n",
    "# check cluster status\n",
    "res = check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 1 - Container Management\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Teradata Vantage Python Client Library provides simple, powerful methods for the creation and maintenance of custom Python runtime environments <b>in the VantageCloud environment</b> .  This allows practitioners complete control over the behavior and quality of their model performance and analytic accuracy running on the Analytic Cluster.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Custom environments are persistent.</b> Users only need to create these once and then can be saved, updated, or modified only as needed.</p>\n",
    "\n",
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Container Management Process</b></p>\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '40%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Create a unique User Environment based on available base images</li>\n",
    "                <br>\n",
    "                <li>Install libraries</li>\n",
    "                <br>\n",
    "                <li>Install models and additional user artifacts</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td><img src = 'images/OAF_Env.png' width = '600'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.  Connect to the Environment Service</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To better support integration with Cloud Services and commong automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "    print('Existing valid UES token')\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e) or '''Failed to execute get_env''' in str(e):\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.  Create a Custom Container in Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If desired, the user can create a <b>new</b> custom environment by starting with a \"base\" image and customizing it.  The steps are:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>List the available \"base\" images the system supports</li>\n",
    "    <li>List any existing \"custom\" environments the user has created</li>\n",
    "    <li>If there are no custom environments, then create a new one from a base image</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new environment, or connect to an existing one\n",
    "\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print('Use an existing environment, or create a new one:')\n",
    "print(f'OAF Environment is set to {oaf_name}.')\n",
    "print('Enter to accept, or input a new value.')\n",
    "print('If the environment is not in the list, an new one will be created')\n",
    "i = input()\n",
    "if len(i) != 0:\n",
    "    oaf_name = i\n",
    "    print(f'OAF Environment is now {oaf_name}')\n",
    "\n",
    "try:\n",
    "    demo_env = create_env(env_name = oaf_name,\n",
    "                      base_env = f'python_{python_version}',\n",
    "                      desc = 'OAF Demo env for LLM')\n",
    "except Exception as e:\n",
    "    if str(e).find('same name already exists') > 0:\n",
    "        print('Environment already exists, obtaining a reference to it')\n",
    "        demo_env = get_env(oaf_name)\n",
    "        pass\n",
    "    elif 'Invalid value for base environment name' in str(e):\n",
    "        print('Unsupported base environment version, using defaults')\n",
    "        demo_env = create_env(env_name = oaf_name,\n",
    "                      desc = 'OAF Demo env for LLM')\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Note create_env seems to be asynchronous - sleep a bit for it to register\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find('No user environments found') > 0:\n",
    "        print('No user environments found')\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>3.  Install Dependencies</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The second step in the customization process is to install Python package dependencies. This demonstration uses the Hugging Face <a href = 'https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2'>all-MiniLM-L6-v2</a> Sentence Transformer.  Since VantageCloud Lake Analytic Clusters are secured by default against unauthorized access to the outside network, the user can load the required libraries and model using teradataml methods:\n",
    "</p> \n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>List the currently installed models and python libraries</li>\n",
    "    <li><b>If necessary</b>, install any required packages</li>\n",
    "    <li><b>If necessary</b>, install the pre-trained model.  This process takes several steps;\n",
    "        <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Import and download the model</li>\n",
    "            <li>Create a zip archive of the model artifacts</li>\n",
    "            <li>Call the install_model() method to load the model to the container</li>\n",
    "        </ol></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(demo_env.models)\n",
    "\n",
    "# just showing a sample here - remove .head(5) to see them all\n",
    "ipydisplay(demo_env.libs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>A note on package versions</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The next demonstration makes use of the DataFrame apply() method, which automatically passes the python code to the Analytic Cluster.  As such, one needs to ensue the python package versions match.  dill and pandas are required, as is any additional libraries for the use case.\n",
    "</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note</b> while not required for many OAF use cases, for this demo the required packages for the model execution must be installed in the local environment first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any Python add-ons needed by the script in the user environment\n",
    "# Using option asynchronous=True for an asychronous execution of the statement.\n",
    "# Note: Avoid asynchronous installation when batch-executing all notebook statements,\n",
    "#       as execution will continue even without installation being complete.\n",
    "#\n",
    "# Can install by passing a list of packages/versions\n",
    "#   Or \n",
    "# install using a requirements.txt file.\n",
    "\n",
    "# For this demo, \n",
    "# this code block will collect the current user's package versions\n",
    "# for installation into the container\n",
    "# when using dataframe.apply(), it pandas and dill are required\n",
    "# to reduce issues, match the version between client and container\n",
    "\n",
    "# import these functions inside of a function namespace\n",
    "def get_versions(pkgs):\n",
    "    local_v_pkgs = []\n",
    "    for p in pkgs:\n",
    "\n",
    "        #fix up any hyphened package names\n",
    "        p_fixed = p.replace('-', '_')\n",
    "\n",
    "        #import the packages and append the strings to the list\n",
    "        exec(f'''import {p_fixed}; local_v_pkgs.append('{p}==' + str({p_fixed}.__version__))''')\n",
    "    return local_v_pkgs\n",
    "\n",
    "v_pkgs = get_versions(pkgs)\n",
    "\n",
    "\n",
    "\n",
    "# check to see if these packages need to be installed\n",
    "# by comparing the len of the intersection of the list of required packages with the installed ones\n",
    "if not len(set([x.split('==')[0] for x in pkgs]).intersection(demo_env.libs['name'].to_list())) == len(pkgs):\n",
    "    \n",
    "    # pass the list of packages - split off any extra info from the version property e.g., plus sign\n",
    "    claim_id = demo_env.install_lib([x.split('+')[0] for x in v_pkgs], asynchronous=True)\n",
    "else:\n",
    "    print(f'All required packages are installed in the {oaf_name} environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Monitor library installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optionally - users can monitor the library installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try: \n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    while stage == 'Started':\n",
    "        stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print('No installations to monitor')\n",
    "\n",
    "    \n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Download and install model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Open Analytics Framework containers do not have open access to the external network, which contributes to a very secure runtime environment.  As such, users will load pre-trained models using the below APIs.  For illustration purposes, the following code will check to see if the model archive exists locally and if it doesn't, will import and download it by creating a model object.  The archive will then be created and installed into the remote environment.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the model needs to be downloaded/archived\n",
    "\n",
    "# construct the file name for the model:\n",
    "model_fname = 'models--' + model_name.replace('/', '--')\n",
    "\n",
    "if not os.path.isfile(f'{model_fname}.zip'):\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import shutil\n",
    "    print('Creating Model Archive...')\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    shutil.make_archive(model_fname, \n",
    "                        format='zip', \n",
    "                        root_dir=f'{expanduser(\"~\")}/.cache/huggingface/hub/{model_fname}/')\n",
    "else:\n",
    "    print('Local model archive exists.')\n",
    "\n",
    "# check to see if the model is already installed\n",
    "try:\n",
    "    if demo_env.models.empty: # no models installed at all\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_fname}.zip', asynchronous = True)\n",
    "    elif not any(model_fname in x for x in demo_env.models['Model']): #see if model is there\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_fname}.zip', asynchronous = True)\n",
    "    else:\n",
    "        print('Model already installed')\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'empty''' in str(e):\n",
    "        print('Installing Model...')\n",
    "        claim_id = demo_env.install_model(model_path = f'{model_fname}.zip', asynchronous = True)\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Monitor model installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optionally - users can monitor the model installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try: \n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "    while stage != 'File Installed':\n",
    "        stage = demo_env.status(claim_id)['Stage'].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print('No installations to monitor')\n",
    "\n",
    "    \n",
    "# Verify the model has been installed correctly.\n",
    "demo_env.refresh()\n",
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Environment Management</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can perform a <b>one-time</b> configuration task to prepare a custom environment for analytic processing at scale.  Once this configuration is complete, these containers can be re-used in ad-hoc development tasks, or used for operationalizing analytics in production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 2 - Developing a massively-scalable AI-powered analytic pipeline\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate how simple it is to utilize common Python design patterns to create a vector embedding function.  This function can then be applied <b>directly</b> to the data in Vantage to run at scale on a GPU-enabled analytic cluster.</p>\n",
    "\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Write a <b>local</b> function that leverages a pre-trained Language Model to create vector embeddings</li>\n",
    "                <br>\n",
    "                <li>Push this processing to the <b>GPU Analytic Cluster</b> for processing at scale</li>\n",
    "                <br>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/local_remote_functions.png'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Check database and UES connection</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e) or '''Failed to execute get_env''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 1.  Create a client-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of this exercise is to create a client-side function which can be \"pushed\" to the analytic cluster for processing at scale.  There are a few minor enhancements here to improve performance and usability in this remote environment:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Imports</b>.  By default, the teradataml python client will package the code, objects, and dependencies and serialize it to the analytic cluster.  Users can make this more efficient by staging these objects before hand (done in the first demo of this notebook).  <b>Important</b> - place the larger libraries (sentence_transformers and torch) inside the function so they won't be registered as new dependencies that need to be installed.</li>\n",
    "    <li><b>GPU Drivers</b>.  Since this function will run both on the client (CPU) and cluster (GPU), place a conditional to check</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings(row):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    \n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    # check for NVIDIA drivers\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # create series from the embeddings list that is returned\n",
    "    s = pd.Series(model.encode(row['comment_text'], device = device))\n",
    "    \n",
    "    #concat them together\n",
    "    row = pd.concat([row, s], axis = 0)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Call the function on local data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Python pandas provides an apply() method to execute the function across all rows in the DataFrame</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'comment_id':[1,2], 'comment_text':['hello world', 'hello back']})\n",
    "\n",
    "df.apply(create_embeddings, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 2. Push this function to the analytic cluster</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Similar to pandas, the teradataml package provides an apply() method which is called in a similar manner, except it runs <b>in parallel on</b> the cluster, leveraging the GPU infrastructure and the MPP processing capabilities of Vantage.</p>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.1 - Inspect the Data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple DataFrame methods to show the data.  A teradataml DataFrame behaves like a normal pandas DataFrame, with one significant difference in that it is a reference to data on the analytic database.  This allows developers to perform familiar data mangement operations on extremely large data sets as if the data is local.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_comments = DataFrame('\"demo_ofs\".\"web_comment\"')\n",
    "\n",
    "ipydisplay(tdf_comments.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.2 - Prepare to execute the apply method</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When using the teradataml apply method,there are some differences in how data is passed in and out of the multiple runtime containers on the distributed nodes.  This offers a great deal of processing power, but also requires some additional considerations when calling the method:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Optional Return Types</b>.  If the data being returned by the function has different columns/data types than the input DataFrame, the user passes these as dictionary value to the keyword argument</li>\n",
    "    <li><b>Data Preparation</b>.  Of course, data preparation and cleansing can be performed inside the function. However, the unique architecture of the <b>Teradata Vantage</b> analytic database, is that users can execute powerful native data preparation functions that will operate at extreme scale and performance</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "types_dict = OrderedDict({})\n",
    "types_dict['comment_id'] = BIGINT()\n",
    "types_dict['comment_text'] = VARCHAR(1000)\n",
    "\n",
    "for i in range(384):\n",
    "    key = '\"' + str(i) + '\"'\n",
    "    types_dict[key] = FLOAT()\n",
    "\n",
    "tdf = DataFrame.from_query('''SELECT TOP 100 comment_id,\n",
    "    CASE \n",
    "        WHEN comment_text IS NULL THEN ' '\n",
    "        ELSE OREPLACE(OREPLACE(OREPLACE(OREPLACE(OREPLACE(comment_text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END comment_text \n",
    "    FROM demo_ofs.web_comment WHERE comment_text <> '';''')\n",
    "\n",
    "tdf.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.3 - Execute the function on the nodes</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Call the apply method on the teradataml DataFrame.  This will push the function to the analytic nodes for processing in parallel.  Data is returned as another teradataml DataFrame, which represents the entire result set of the operation.  For this example, additional method arguments include:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Function</b>.  The name of the function to pass - this is the original client-side function written above</li>\n",
    "    <li><b>Environment</b>.  The custom runtime environment with the models and dependencies loaded</li>\n",
    "    <li><b>Return types</b>. OrderedDict that represents the column names and data types</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe representing the embeddings\n",
    "tdf_embedded = tdf.apply(lambda row: create_embeddings(row),\n",
    "                    env_name = demo_env, \n",
    "                    returns = types_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check the data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now - users can create a table with these embeddings, use it in additional analytics, or operationalize this as part of a pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(tdf_embedded.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - executing custom code against GPU-enabled analytic clusters</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed how users can use simple, familiar patters to execute powerful AI models <b>at scale</b> for development and operational processing.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Stop the Cluster</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Hibernate the environment if desired</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demo 3 - Operationalizing AI-powered analytics\n",
    "  <br>\n",
    "    </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following demonstration will illustrate how developers can take the next step in the process to <b>operationalize</b> this processing, enabling the entire organization to leverage AI across the data lifecycle, including</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "               <li><b>Prepare the environment</b>.  Package the scoring function into a more robust program, and stage it on the remote environment</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Python Pipeline</b>.  Execute the function using Python methods</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>SQL Pipeline</b>.  Execute the function using SQL - allowing for broad adoption and use in ETL and operational needs</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/OAF_Ops.png' width = 350 ></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Check connection</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Reconnect to the database, UES, and start cluster if necessary<get_context()/p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection\n",
    "eng = check_and_connect(host=host, username=username, password=password, compute_group = compute_group)\n",
    "print(eng)\n",
    "    \n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "# if not, authenticate\n",
    "try:\n",
    "    demo_env = get_env(oaf_name)\n",
    "\n",
    "except Exception as e:\n",
    "    if '''NoneType' object has no attribute 'value''' in str(e) or '''Failed to execute get_env''' in str(e): #UES auth expired/required\n",
    "        if set_auth_token(ues_url = ues_url, username = username, pat_token = pat_token, pem_file = pem_file):\n",
    "            print('UES Authentication successful')\n",
    "            try:\n",
    "                demo_env = get_env(oaf_name)\n",
    "                pass\n",
    "            except Exception as l:\n",
    "                if f'''User environment '{oaf_name}' not found''' in str(l):\n",
    "                    print('User environment not found')\n",
    "                    pass\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('UES Authentication failed, check URL and account info')\n",
    "        pass\n",
    "    elif f'''User environment '{oaf_name}' not found''' in str(e):\n",
    "        print('User environment not found')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# check cluster status\n",
    "check_cluster_start(compute_group = compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 2.  Create a server-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of this exercise is to create a <b>server-side</b> function which can be staged on the analytic cluster.  This offers many improvements over the method used above;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Performance</b>.  Staging the code and dependencies in the container environment reduces the amount of I/O, since the function doesn't need to get serialized to the cluster when called</li>\n",
    "    <li><b>Operationalization</b>.  The execution pipeline can be encapsulated into a SQL statement, which allows for seamless use in ETL pipelines, dashboards, or applications that need access</li>\n",
    "    <li><b>Flexibility</b>. Developers can express much greater flexibility in how the code works to optimize for performance, stability, data cleanliness or flow logic</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>These benefits do come with some amount of additional work.  Developers need to account how data is passed in and out of the code runtime, and how to pass it back to the SQL engine to assemble and return the final resultset.  Code is executed when the user expresses an <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>APPLY SQL function</a>;</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Input Query</b>.  The APPLY function takes a SQL query as input.  This query can be as complex as needed and include data preparation, cleansing, and/or any other set-based logic necessary to create the desired input data set.  This complexity can also be abstracted into a database view.  When using the teradata client connectors for Python or R, thise query is represented as a DataFrame or tibble.</li>\n",
    "    <li><b>Pre-processing</b>.  Based on the query plan, data is retrieved from storage (cache, block storage, or object storage) and the input query is executed.</li>\n",
    "    <li><b>Distribution</b>.  Input data can be partitioned and/or ordered to be processed on a specific container or collection of them.  For example, the user may want to process all data for a single post code in one partition, and run thousands of these in parallel.  Data can also be distributed evenly across all units of parallelism in the system</li>\n",
    "    <li><b>Input</b>.  The data for each container is passed to the runtime using tandard input (stdin)</li>\n",
    "    <li><b>Processing</b>.  The user's code executes, parsing stdin for the input data</li>\n",
    "    <li><b>Output</b>.  Data is sent out of the code block using standard output (stdout)</li>\n",
    "    <li><b>Resultset</b>.  Resultset is assembled by the analytic database, and the SQL query returns</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Example server-side code block</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This is the python script used in the demonstration.  It is saved to the filesystem as \"embedding.py\".  Note here the original client-side processing function has been reused, and the additional logic is for input, output, and error handling.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import sys, csv\n",
    "import warnings\n",
    "import torch \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Read data from stdin, and construct a Pandas DataFrame #\n",
    "# Data can also be read/processed directly from stdin if desired\n",
    "\n",
    "# 1. use the csv reader to parse comma-separated input\n",
    "# 2. construct the Dataframe from the resulting dictionary\n",
    "\n",
    "colNames = ['comment_id', 'comment_text']\n",
    "d = csv.DictReader(sys.stdin.readlines(), fieldnames = colNames)\n",
    "df = pd.DataFrame(d, columns = colNames)\n",
    "\n",
    "# Use try...except to produce an error if something goes wrong in the try block\n",
    "try:\n",
    "    # Exit gracefully if DataFrame is empty\n",
    "    # It is possible some partitions won't get any data\n",
    "    if df.empty:\n",
    "        sys.exit()\n",
    "    \n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    # execute the same logic as in the demo function\n",
    "    \n",
    "    def create_embeddings(row):\n",
    "        # check for NVIDIA drivers\n",
    "        if torch.cuda.is_available(): device = 'cuda'  \n",
    "        else: device = None\n",
    "            \n",
    "        # create series from the embeddings list that is returned\n",
    "        s = pd.Series(model.encode(row['comment_text'], device = device))\n",
    "    \n",
    "        #concat them together\n",
    "        row = pd.concat([row, s], axis = 0)\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    #call the embedding function using pandas apply()\n",
    "    df = df.apply(create_embeddings, axis = 1) \n",
    "\n",
    "\n",
    "    # Egress results to the Database through standard output.\n",
    "    # iterrrows generates a Series, iterate through the series to construct\n",
    "    # a comma-separated output string\n",
    "    for index, value in df.iterrows():\n",
    "        my_str = ''\n",
    "        for val in value.index:\n",
    "            my_str = my_str + str(value[val]) + ','\n",
    "        print(my_str[:-1])\n",
    "        \n",
    "# raise any errors back to the SQL engine\n",
    "except (SystemExit):\n",
    "    # Skip exception if system exit requested in try block\n",
    "    pass\n",
    "except:    # Specify in standard error any other error encountered\n",
    "    print(\"Script Failure :\", sys.exc_info()[0], file=sys.stderr)\n",
    "    raise\n",
    "    sys.exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 3.  Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the install_file() method to install this python file to the container.  As a reminder, this container is persistent, so these steps need only be done infrequently.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_env.install_file('embedding.py', replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 4.  Call the APPLY function </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This function can be executed in two ways;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/teradataml-Apply-Class-for-APPLY-Table-Operator'>Python</a></b> by calling the Apply() module function</li>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>SQL</a></b> which allows for broad adoption across the enterprise</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>APPLY using Python</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The process is as follows</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Construct a dictionary that will define the return columns and data types</li>\n",
    "    <li>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic <b>in-database</b></li>\n",
    "    <li>Execute the module function.  This constructs the function call in the database, but does not execute anything.  Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "    <li>In order to execute the function, an \"execute_script()\" method must be called.  This method returns the server-side DataFrame representing the complete operation.  This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_dict = OrderedDict({})\n",
    "types_dict['comment_id'] = BIGINT()\n",
    "types_dict['comment_text'] = VARCHAR(1000)\n",
    "\n",
    "for i in range(384):\n",
    "    key = '\"' + str(i) + '\"'\n",
    "    types_dict[key] = FLOAT()\n",
    "\n",
    "tdf = DataFrame.from_query('''SELECT TOP 1000 comment_id,\n",
    "    CASE \n",
    "        WHEN comment_text IS NULL THEN ' '\n",
    "        ELSE OREPLACE(OREPLACE(OREPLACE(OREPLACE(OREPLACE(comment_text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END comment_text \n",
    "    FROM demo_ofs.web_comment WHERE comment_text <> '';''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_obj = Apply(data = tdf,\n",
    "                  apply_command = 'python embedding.py',\n",
    "                  returns = types_dict,\n",
    "                  env_name = oaf_name\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Execute the function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>call execute_script(), and return a single record to the client to check the data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(apply_obj.execute_script().sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Step 5. Persist the resultset</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Simple methods for saving the results to a table for reuse.  For this demo, a temporary (volatile) table is created for illustration purposes.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(apply_obj.execute_script(), table_name = 'demo_embeddings', temporary = True, if_exists = 'replace')\n",
    "execute_sql('SELECT TOP 1 comment_text, \"0\", \"1\" FROM demo_embeddings;').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>APPLY using SQL</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The process is much the same, except the benefit is that this SQL can be used by a wide range of tools, applications, and dashboards; as well as automated processes.  Construct the statement using the following values:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>\n",
    "        <b>ON</b> Clause<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li>Input table or query</li>\n",
    "        <li>Hash or Partition column(s)</li>\n",
    "        <li>Order by and/pr local order by directives</li>\n",
    "        <li>Return columns and data types</li></ul></li>\n",
    "    <li>Any partition column(s)</li>\n",
    "    <li>The shell command to run</li>\n",
    "    <li>Additional functional arguments</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Simplify the SQL using Views</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create a view that represents the data preparation steps.  In this example, the preparation tasks include removing NULLs and any special characters.  Note the same SQL used to contstruct the teradataml DataFrame is used here.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "    REPLACE VIEW prepared_data_V AS\n",
    "    \n",
    "    SELECT TOP 1000 \n",
    "    comment_id,\n",
    "    CASE \n",
    "        WHEN comment_text IS NULL THEN ' '\n",
    "        ELSE OREPLACE(OREPLACE(OREPLACE(OREPLACE(OREPLACE(comment_text , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END comment_text \n",
    "    FROM demo_ofs.web_comment WHERE comment_text <> '';\n",
    "    \n",
    "    '''\n",
    "\n",
    "# execute the sql against the database\n",
    "execute_sql(qry)\n",
    "\n",
    "# check the data\n",
    "execute_sql('SELECT TOP 1 * FROM prepared_data_V;').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Construct the APPLY Query</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use the view as input data, provide \"returns\" payload and required parameters.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = f'''\n",
    "SELECT * FROM Apply(\n",
    "    ON prepared_data_V\n",
    "    PARTITION BY ANY\n",
    "    \n",
    "    returns(comment_id BIGINT, comment_text VARCHAR(1000), \"0\" FLOAT, \"1\" FLOAT, \"2\" FLOAT, \"3\" FLOAT, \"4\" FLOAT, \"5\" FLOAT, \"6\" FLOAT, \"7\" FLOAT, \"8\" FLOAT, \"9\" FLOAT, \"10\" FLOAT, \"11\" FLOAT, \"12\" FLOAT, \"13\" FLOAT, \"14\" FLOAT, \"15\" FLOAT, \"16\" FLOAT, \"17\" FLOAT, \"18\" FLOAT, \"19\" FLOAT, \"20\" FLOAT, \"21\" FLOAT, \"22\" FLOAT, \"23\" FLOAT, \"24\" FLOAT, \"25\" FLOAT, \"26\" FLOAT, \"27\" FLOAT, \"28\" FLOAT, \"29\" FLOAT, \"30\" FLOAT, \"31\" FLOAT, \"32\" FLOAT, \"33\" FLOAT, \"34\" FLOAT, \"35\" FLOAT, \"36\" FLOAT, \"37\" FLOAT, \"38\" FLOAT, \"39\" FLOAT, \"40\" FLOAT, \"41\" FLOAT, \"42\" FLOAT, \"43\" FLOAT, \"44\" FLOAT, \"45\" FLOAT, \"46\" FLOAT, \"47\" FLOAT, \"48\" FLOAT, \"49\" FLOAT, \"50\" FLOAT, \"51\" FLOAT, \"52\" FLOAT, \"53\" FLOAT, \"54\" FLOAT, \"55\" FLOAT, \"56\" FLOAT, \"57\" FLOAT, \"58\" FLOAT, \"59\" FLOAT, \"60\" FLOAT, \"61\" FLOAT, \"62\" FLOAT, \"63\" FLOAT, \"64\" FLOAT, \"65\" FLOAT, \"66\" FLOAT, \"67\" FLOAT, \"68\" FLOAT, \"69\" FLOAT, \"70\" FLOAT, \"71\" FLOAT, \"72\" FLOAT, \"73\" FLOAT, \"74\" FLOAT, \"75\" FLOAT, \"76\" FLOAT, \"77\" FLOAT, \"78\" FLOAT, \"79\" FLOAT, \"80\" FLOAT, \"81\" FLOAT, \"82\" FLOAT, \"83\" FLOAT, \"84\" FLOAT, \"85\" FLOAT, \"86\" FLOAT, \"87\" FLOAT, \"88\" FLOAT, \"89\" FLOAT, \"90\" FLOAT, \"91\" FLOAT, \"92\" FLOAT, \"93\" FLOAT, \"94\" FLOAT, \"95\" FLOAT, \"96\" FLOAT, \"97\" FLOAT, \"98\" FLOAT, \"99\" FLOAT, \"100\" FLOAT, \"101\" FLOAT, \"102\" FLOAT, \"103\" FLOAT, \"104\" FLOAT, \"105\" FLOAT, \"106\" FLOAT, \"107\" FLOAT, \"108\" FLOAT, \"109\" FLOAT, \"110\" FLOAT, \"111\" FLOAT, \"112\" FLOAT, \"113\" FLOAT, \"114\" FLOAT, \"115\" FLOAT, \"116\" FLOAT, \"117\" FLOAT, \"118\" FLOAT, \"119\" FLOAT, \"120\" FLOAT, \"121\" FLOAT, \"122\" FLOAT, \"123\" FLOAT, \"124\" FLOAT, \"125\" FLOAT, \"126\" FLOAT, \"127\" FLOAT, \"128\" FLOAT, \"129\" FLOAT, \"130\" FLOAT, \"131\" FLOAT, \"132\" FLOAT, \"133\" FLOAT, \"134\" FLOAT, \"135\" FLOAT, \"136\" FLOAT, \"137\" FLOAT, \"138\" FLOAT, \"139\" FLOAT, \"140\" FLOAT, \"141\" FLOAT, \"142\" FLOAT, \"143\" FLOAT, \"144\" FLOAT, \"145\" FLOAT, \"146\" FLOAT, \"147\" FLOAT, \"148\" FLOAT, \"149\" FLOAT, \"150\" FLOAT, \"151\" FLOAT, \"152\" FLOAT, \"153\" FLOAT, \"154\" FLOAT, \"155\" FLOAT, \"156\" FLOAT, \"157\" FLOAT, \"158\" FLOAT, \"159\" FLOAT, \"160\" FLOAT, \"161\" FLOAT, \"162\" FLOAT, \"163\" FLOAT, \"164\" FLOAT, \"165\" FLOAT, \"166\" FLOAT, \"167\" FLOAT, \"168\" FLOAT, \"169\" FLOAT, \"170\" FLOAT, \"171\" FLOAT, \"172\" FLOAT, \"173\" FLOAT, \"174\" FLOAT, \"175\" FLOAT, \"176\" FLOAT, \"177\" FLOAT, \"178\" FLOAT, \"179\" FLOAT, \"180\" FLOAT, \"181\" FLOAT, \"182\" FLOAT, \"183\" FLOAT, \"184\" FLOAT, \"185\" FLOAT, \"186\" FLOAT, \"187\" FLOAT, \"188\" FLOAT, \"189\" FLOAT, \"190\" FLOAT, \"191\" FLOAT, \"192\" FLOAT, \"193\" FLOAT, \"194\" FLOAT, \"195\" FLOAT, \"196\" FLOAT, \"197\" FLOAT, \"198\" FLOAT, \"199\" FLOAT, \"200\" FLOAT, \"201\" FLOAT, \"202\" FLOAT, \"203\" FLOAT, \"204\" FLOAT, \"205\" FLOAT, \"206\" FLOAT, \"207\" FLOAT, \"208\" FLOAT, \"209\" FLOAT, \"210\" FLOAT, \"211\" FLOAT, \"212\" FLOAT, \"213\" FLOAT, \"214\" FLOAT, \"215\" FLOAT, \"216\" FLOAT, \"217\" FLOAT, \"218\" FLOAT, \"219\" FLOAT, \"220\" FLOAT, \"221\" FLOAT, \"222\" FLOAT, \"223\" FLOAT, \"224\" FLOAT, \"225\" FLOAT, \"226\" FLOAT, \"227\" FLOAT, \"228\" FLOAT, \"229\" FLOAT, \"230\" FLOAT, \"231\" FLOAT, \"232\" FLOAT, \"233\" FLOAT, \"234\" FLOAT, \"235\" FLOAT, \"236\" FLOAT, \"237\" FLOAT, \"238\" FLOAT, \"239\" FLOAT, \"240\" FLOAT, \"241\" FLOAT, \"242\" FLOAT, \"243\" FLOAT, \"244\" FLOAT, \"245\" FLOAT, \"246\" FLOAT, \"247\" FLOAT, \"248\" FLOAT, \"249\" FLOAT, \"250\" FLOAT, \"251\" FLOAT, \"252\" FLOAT, \"253\" FLOAT, \"254\" FLOAT, \"255\" FLOAT, \"256\" FLOAT, \"257\" FLOAT, \"258\" FLOAT, \"259\" FLOAT, \"260\" FLOAT, \"261\" FLOAT, \"262\" FLOAT, \"263\" FLOAT, \"264\" FLOAT, \"265\" FLOAT, \"266\" FLOAT, \"267\" FLOAT, \"268\" FLOAT, \"269\" FLOAT, \"270\" FLOAT, \"271\" FLOAT, \"272\" FLOAT, \"273\" FLOAT, \"274\" FLOAT, \"275\" FLOAT, \"276\" FLOAT, \"277\" FLOAT, \"278\" FLOAT, \"279\" FLOAT, \"280\" FLOAT, \"281\" FLOAT, \"282\" FLOAT, \"283\" FLOAT, \"284\" FLOAT, \"285\" FLOAT, \"286\" FLOAT, \"287\" FLOAT, \"288\" FLOAT, \"289\" FLOAT, \"290\" FLOAT, \"291\" FLOAT, \"292\" FLOAT, \"293\" FLOAT, \"294\" FLOAT, \"295\" FLOAT, \"296\" FLOAT, \"297\" FLOAT, \"298\" FLOAT, \"299\" FLOAT, \"300\" FLOAT, \"301\" FLOAT, \"302\" FLOAT, \"303\" FLOAT, \"304\" FLOAT, \"305\" FLOAT, \"306\" FLOAT, \"307\" FLOAT, \"308\" FLOAT, \"309\" FLOAT, \"310\" FLOAT, \"311\" FLOAT, \"312\" FLOAT, \"313\" FLOAT, \"314\" FLOAT, \"315\" FLOAT, \"316\" FLOAT, \"317\" FLOAT, \"318\" FLOAT, \"319\" FLOAT, \"320\" FLOAT, \"321\" FLOAT, \"322\" FLOAT, \"323\" FLOAT, \"324\" FLOAT, \"325\" FLOAT, \"326\" FLOAT, \"327\" FLOAT, \"328\" FLOAT, \"329\" FLOAT, \"330\" FLOAT, \"331\" FLOAT, \"332\" FLOAT, \"333\" FLOAT, \"334\" FLOAT, \"335\" FLOAT, \"336\" FLOAT, \"337\" FLOAT, \"338\" FLOAT, \"339\" FLOAT, \"340\" FLOAT, \"341\" FLOAT, \"342\" FLOAT, \"343\" FLOAT, \"344\" FLOAT, \"345\" FLOAT, \"346\" FLOAT, \"347\" FLOAT, \"348\" FLOAT, \"349\" FLOAT, \"350\" FLOAT, \"351\" FLOAT, \"352\" FLOAT, \"353\" FLOAT, \"354\" FLOAT, \"355\" FLOAT, \"356\" FLOAT, \"357\" FLOAT, \"358\" FLOAT, \"359\" FLOAT, \"360\" FLOAT, \"361\" FLOAT, \"362\" FLOAT, \"363\" FLOAT, \"364\" FLOAT, \"365\" FLOAT, \"366\" FLOAT, \"367\" FLOAT, \"368\" FLOAT, \"369\" FLOAT, \"370\" FLOAT, \"371\" FLOAT, \"372\" FLOAT, \"373\" FLOAT, \"374\" FLOAT, \"375\" FLOAT, \"376\" FLOAT, \"377\" FLOAT, \"378\" FLOAT, \"379\" FLOAT, \"380\" FLOAT, \"381\" FLOAT, \"382\" FLOAT, \"383\" FLOAT)\n",
    "    USING\n",
    "    \n",
    "    APPLY_COMMAND('python embedding.py')\n",
    "    ENVIRONMENT('{oaf_name}')\n",
    "    STYLE('csv')\n",
    "    delimiter(',') \n",
    ") as d;'''\n",
    "\n",
    "\n",
    "# execute the query on the server, and return the first four columns of the first record\n",
    "execute_sql(qry).fetchone()[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Simplify the APPLY using a view</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Construct a database view using the query above.  Now this simple query can be embedded in operational processing, ETL functions, or the like.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_qry = f'''REPLACE VIEW simplified_apply_V AS {qry}\n",
    "'''\n",
    "\n",
    "execute_sql(view_qry);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT TOP 10 * FROM simplified_apply_V', eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:24px;font-family:Arial;color:#00233C'><b>Conclusion - Operationalizing AI-powered analytics</b></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The preceding demo showed two methods for operationalizing the model execution; using python syntax, or embedding it as a simplified SQL view.  The former allows for developers and data scientists to easily embed this processing in their existing or new applications and workflows.  The latter allows for broad, democratized adoption across the data lifecycle and enterprise - enabling this analytic processing in ETL for data prep and transformation tasks, and in production to power dashboards and/or BI tools.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Cleanup</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Stop the cluster, remove the environment (if desired), and drop views created in the demonstrations.  Finally, disconnect from the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninstall the libraries from the environment first before removing it\n",
    "# demo_env.uninstall_lib(libs = demo_env.libs['name'].to_list())\n",
    "# remove_env(oaf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql('DROP VIEW simplified_apply_V;');\n",
    "execute_sql('DROP VIEW prepared_data_V;');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
